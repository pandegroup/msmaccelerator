














<html><head><title>parrot_run_hdfs(1)</title></head><body><h1>parrot_run_hdfs(1)</h1>
<h2>NAME</h2>
<b>parrot_run_hdfs</b> - run a program in the Parrot virtual file system with HDFS client setup

<h2>SYNOPSIS</h2>
<tt><b>parrot_run_hdfs [parrot_options] program [program_options]</b></tt>

<h2>DESCRIPTION</h2>
<p>
<tt>parrot_run_hdfs</tt> runs an application or a shell inside the Parrot virtual filesystem. 

<p>
HDFS is the primary distributed filesystem used in the Hadoop project. Parrot
supports read and write access to HDFS systems using the parrot_run_hdfs
wrapper. The command checks that the appropriate environmental variables are
defined and calls <tt>parrot_run</tt>. See <a href=parrot_run.html>parrot_run(1)</a>.

<p>
In particular, you must ensure that you define the following environmental variables:

<dir>
<li><tt><b>JAVA_HOME</b></tt> Location of your Java installation.
<li><tt><b>HADOOP_HOME</b></tt> Location of your Hadoop installation.
</dir>

<p>
Based on these environmental variables, <tt>parrot_run_hdfs</tt> will attempt to
find the appropriate paths for <tt>libjvm.so</tt> and <tt>libhdfs.so</tt>. These
paths are stored in the environmental variables <tt>LIBJVM_PATH</tt> and
<tt>LIBHDFS_PATH</tt>, which are used by the HDFS Parrot module to load the
necessary shared libraries at run-time. To avoid the startup overhead of
searching for these libraries, you may set the paths manually in your
environment before calling <tt>parrot_run_hdfs</tt>, or you may edit the script
directly.

<p>
Note that while Parrot supports read access to HDFS, it only provides
write-once support on HDFS. This is because the current implementations of HDFS
do not provide reliable append operations. Likewise, files can only be opened
in either read (O_RDONLY) or write mode (O_WRONLY), and not both (O_RDWR).

<p>
For complete details with examples, see the <a href=http://www.nd.edu/~ccl/software/manuals/parrot.html>Parrot User's Manual</a>

<h2>OPTIONS</h2>
<p>
See <a href=parrot_run.html>parrot_run(1)</a> for option listing.

<h2>ENVIRONMENT VARIABLES</h2>

<dir>
<li><tt><b>JAVA_HOME</b></tt> Location of your Java installation.
<li><tt><b>HADOOP_HOME</b></tt> Location of your Hadoop installation.
</dir>

<h2>EXIT STATUS</h2>
<tt>parrot_run_hdfs</tt> returns the exit status of the process that it runs.
If <tt>parrot_run_hdfs</tt> is unable to start the process, it will return non-zero.

<h2>EXAMPLES</h2>
To access a single remote HDFS file using <tt>cat</tt>:
<pre>
% parrot_run_hdfs cat /hdfs/server:port/foo
</pre>

You can also run an entire shell inside of Parrot, like this:
<pre>
% parrot_run_hdfs bash
% cd /hdfs/server:port/
% ls -la
% cat foo
</pre>

<h2>COPYRIGHT</h2>

The Cooperative Computing Tools are Copyright (C) 2003-2004 Douglas Thain and Copyright (C) 2005-2011 The University of Notre Dame.  This software is distributed under the GNU General Public License.  See the file COPYING for details.

<h2>SEE ALSO</h2>

<dir>
<li> <a href="../index.html">Cooperative Computing Tools Documentation</a>
<li> <a href="../parrot.html">Parrot User Manual</a>
<li> <a href=parrot_run.html>parrot_run(1)</a>
<li> <a href=parrot_run_hdfs.html>parrot_run_hdfs(1)</a>
<li> <a href=parrot_cp.html>parrot_cp(1)</a>
<li> <a href=parrot_getacl.html>parrot_getacl(1)</a>
<li> <a href=parrot_setacl.html>parrot_setacl(1)</a>
<li> <a href=parrot_mkalloc.html>parrot_mkalloc(1)</a>
<li> <a href=parrot_lsalloc.html>parrot_lsalloc(1)</a>
<li> <a href=parrot_locate.html>parrot_locate(1)</a>
<li> <a href=parrot_timeout.html>parrot_timeout(1)</a>
<li> <a href=parrot_whoami.html>parrot_whoami(1)</a>
<li> <a href=parrot_md5.html>parrot_md5(1)</a>
</dir>

<p><hr>CCTools 3.4.2 released on 02/10/2012</body></html>

